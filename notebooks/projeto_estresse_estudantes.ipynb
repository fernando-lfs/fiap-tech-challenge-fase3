{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f8dbf4a",
   "metadata": {},
   "source": [
    "# üìä Tech Challenge - An√°lise e Previs√£o de Fatores de Estresse em Estudantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317e296c",
   "metadata": {},
   "source": [
    "## üìù Defini√ß√£o do problema\n",
    "\n",
    "* **Problema de Neg√≥cio:** Institui√ß√µes de ensino precisam identificar estudantes em risco de estresse elevado para oferecer suporte adequado no momento certo. Este projeto visa criar uma solu√ß√£o preditiva que auxilie nessa identifica√ß√£o, permitindo interven√ß√µes mais direcionadas e eficazes.\n",
    "* **Objetivo T√©cnico:** O problema foi enquadrado como um desafio de **Classifica√ß√£o Multiclasse**. O objetivo √© treinar um modelo de Machine Learning para prever o n√≠vel de estresse de um estudante em uma de tr√™s categorias (0: baixo, 1: m√©dio, 2: alto), utilizando a coluna `stress_level` como vari√°vel-alvo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa96308d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## üìë Sum√°rio\n",
    "1. ‚öôÔ∏è Configura√ß√£o do Ambiente\n",
    "2. üì• Coleta, Armazenamento e Carregamento\n",
    "3. üìä An√°lise Explorat√≥ria de Dados (EDA)\n",
    "4. üßπ Pr√©-processamento e Prepara√ß√£o dos Dados\n",
    "5. ü§ñ Modelagem e Treinamento\n",
    "6. üõ†Ô∏è Otimiza√ß√£o de Hiperpar√¢metros\n",
    "7. üèÅ Conclus√£o\n",
    "\n",
    "# üìñ Sum√°rio do Projeto\n",
    "\n",
    "* [1. ‚öôÔ∏è Configura√ß√£o do Ambiente](#1-configuracao-do-ambiente)\n",
    "* [2. üì• Coleta, Armazenamento e Carregamento](#2-coleta-armazenamento-e-carregamento)\n",
    "* [3. üìä An√°lise Explorat√≥ria de Dados (EDA)](#3-analise-exploratoria-de-dados-eda)\n",
    "* [4. üßπ Pr√©-processamento e Prepara√ß√£o dos Dados](#4-pre-processamento-e-preparacao-dos-dados)\n",
    "* [5. ü§ñ Modelagem e Treinamento](#5-modelagem-e-treinamento)\n",
    "* [6. üõ†Ô∏è Otimiza√ß√£o de Hiperpar√¢metros](#6-otimizacao-de-hiperparametros)\n",
    "* [7. üèÅ Conclus√£o](#7-conclusao)\n",
    "\n",
    "# üìñ Sum√°rio\n",
    "1. [‚öôÔ∏è Configura√ß√£o do Ambiente](#1-configuracao-do-ambiente)\n",
    "2. [üì• Coleta, Armazenamento e Carregamento](#2-coleta-armazenamento-e-carregamento)\n",
    "3. [üìä An√°lise Explorat√≥ria de Dados (EDA)](#3-analise-exploratoria-de-dados-eda)\n",
    "4. [üßπ Pr√©-processamento e Prepara√ß√£o dos Dados](#4-pre-processamento-e-preparacao-dos-dados)\n",
    "5. [ü§ñ Modelagem e Treinamento](#5-modelagem-e-treinamento)\n",
    "6. [üõ†Ô∏è Otimiza√ß√£o de Hiperpar√¢metros](#6-otimizacao-de-hiperparametros)\n",
    "7. [üèÅ Conclus√£o](#7-conclusao)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e91a6d4",
   "metadata": {},
   "source": [
    "# 1. ‚öôÔ∏è Configura√ß√£o do Ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c107ed51",
   "metadata": {},
   "source": [
    "### üìå Prepara√ß√£o do ambiente de trabalho\n",
    "\n",
    "* **1. Importa√ß√£o de Bibliotecas:** Carregamos todas as ferramentas necess√°rias para manipula√ß√£o de dados (pandas), visualiza√ß√£o (matplotlib, seaborn), modelagem (scikit-learn) e outras opera√ß√µes. Centralizar as importa√ß√µes no in√≠cio do notebook √© uma boa pr√°tica que organiza o c√≥digo e deixa claro quais s√£o as depend√™ncias do projeto.\n",
    "* **2. Configura√ß√£o do Projeto:** Adicionamos o diret√≥rio raiz ao path do sistema para permitir a importa√ß√£o de m√≥dulos customizados, como o dicion√°rio FEATURE_TRANSLATOR do arquivo config.py.\n",
    "* **3. Defini√ß√£o de Constantes e Padr√µes:** Estabelecemos constantes globais, como o nome da vari√°vel alvo (TARGET_VARIABLE) e a semente de aleatoriedade (RANDOM_STATE), para garantir consist√™ncia e reprodutibilidade. Tamb√©m definimos um estilo visual padr√£o para todos os gr√°ficos do notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4538c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Importa√ß√£o de Bibliotecas ---\n",
    "\n",
    "# Manipula√ß√£o de dados e sistema\n",
    "import os\n",
    "import sys\n",
    "from io import BytesIO\n",
    "\n",
    "# An√°lise e visualiza√ß√£o\n",
    "import boto3\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Componentes do Scikit-Learn para modelagem e avalia√ß√£o\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# --- 2. Configura√ß√£o do Projeto ---\n",
    "\n",
    "# Adiciona o diret√≥rio raiz ao path para importar modulo de dicion√°rio de tradu√ß√£o dos nomes das features\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from config import FEATURE_TRANSLATOR\n",
    "\n",
    "# --- 3. Padr√µes de Visualiza√ß√£o ---\n",
    "\n",
    "# Define um estilo visual consistente para todos os gr√°ficos do notebook\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "# --- 4. Mensagem de Confirma√ß√£o ---\n",
    "\n",
    "print(\"‚úÖ Ambiente configurado com sucesso.\")\n",
    "print(\n",
    "    f\"   ‚îî‚îÄ‚îÄ Dicion√°rio 'FEATURE_TRANSLATOR' carregado com {len(FEATURE_TRANSLATOR)} tradu√ß√µes.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d223bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Constantes do Projeto ---\n",
    "\n",
    "# Nome da vari√°vel alvo a ser utilizada em todo o notebook\n",
    "TARGET_VARIABLE = \"stress_level\"\n",
    "\n",
    "# Semente rand√¥mica para garantir a reprodutibilidade dos experimentos\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc36980",
   "metadata": {},
   "source": [
    "# 2. üì• Coleta, Armazenamento e Carregamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab32f6df",
   "metadata": {},
   "source": [
    "## üìå Coleta de Dados\n",
    "\n",
    "* **Fonte dos Dados:** Foi utilizado um dataset p√∫blico da plataforma Kaggle, chamado \"Student Stress Factors - A Comprehensive Analysis\".\n",
    "* **Justificativa:** A utiliza√ß√£o de um dataset j√° existente foi uma decis√£o estrat√©gica para otimizar o tempo e concentrar os esfor√ßos do projeto nas etapas de An√°lise, Modelagem e Deploy, que s√£o o foco do desafio.\n",
    "\n",
    "## üìå Armazenamento dos Dados\n",
    "\n",
    "* **Solu√ß√£o Adotada:** Para simular um ambiente de produ√ß√£o e garantir a reprodutibilidade, os dados foram armazenados em um sistema de armazenamento de objetos local (MinIO)].\n",
    "* **Processo:** Um bucket chamado `student-stress` foi criado no servidor MinIO , e o dataset `StressLevelDataset.csv` foi carregado, tornando-se acess√≠vel via servi√ßo para a etapa de an√°lise.\n",
    "\n",
    "## üìå Carregamento dos Dados\n",
    "\n",
    "* **Processo:** O c√≥digo abaixo configura as credenciais de acesso (priorizando vari√°veis de ambiente por seguran√ßa) e estabelece uma conex√£o com o MinIO. Em seguida, ele l√™ o arquivo `StressLevelDataset.csv` diretamente do bucket de armazenamento para um DataFrame do pandas, que √© a estrutura de dados fundamental que usaremos para toda a an√°lise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaedd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Configura√ß√µes de Conex√£o ---\n",
    "# As credenciais s√£o carregadas de vari√°veis de ambiente para seguran√ßa.\n",
    "# Valores padr√£o s√£o fornecidos para facilitar a execu√ß√£o em ambiente local.\n",
    "MINIO_ENDPOINT = os.getenv(\"MINIO_ENDPOINT\", \"127.0.0.1:9000\")\n",
    "MINIO_ACCESS_KEY = os.getenv(\"MINIO_ACCESS_KEY\", \"minioadmin\")\n",
    "MINIO_SECRET_KEY = os.getenv(\"MINIO_SECRET_KEY\", \"minioadmin\")\n",
    "BUCKET_NAME = \"student-stress\"\n",
    "OBJECT_NAME = \"StressLevelDataset.csv\"\n",
    "\n",
    "# --- 2. Carregamento dos Dados ---\n",
    "try:\n",
    "    # Inicializa o cliente S3 para interagir com o MinIO\n",
    "    s3_client = boto3.client(\n",
    "        \"s3\",\n",
    "        endpoint_url=f\"http://{MINIO_ENDPOINT}\",\n",
    "        aws_access_key_id=MINIO_ACCESS_KEY,\n",
    "        aws_secret_access_key=MINIO_SECRET_KEY,\n",
    "        config=boto3.session.Config(signature_version=\"s3v4\"),\n",
    "    )\n",
    "\n",
    "    # Busca o objeto no bucket e o carrega em um DataFrame\n",
    "    response = s3_client.get_object(Bucket=BUCKET_NAME, Key=OBJECT_NAME)\n",
    "    df = pd.read_csv(BytesIO(response[\"Body\"].read()))\n",
    "\n",
    "    print(\n",
    "        f\"‚úÖ Dataset '{OBJECT_NAME}' carregado com sucesso do bucket '{BUCKET_NAME}'.\"\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao carregar o dataset do MinIO: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c5989e",
   "metadata": {},
   "source": [
    "# 3. üìä An√°lise Explorat√≥ria de Dados (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89856bdc",
   "metadata": {},
   "source": [
    "A An√°lise Explorat√≥ria de Dados (EDA) √© uma das etapas fundamentais de qualquer projeto de Machine Learning. √â quando realmente come√ßamos a conhecer os dados: entender como est√£o organizados, descobrir padr√µes escondidos, identificar problemas e extrair os primeiros insights que v√£o orientar todo o trabalho seguinte ‚Äî desde a limpeza at√© a constru√ß√£o dos modelos.\n",
    "Vamos dividir nossa EDA em tr√™s etapas:\n",
    "* **An√°lise Estrutural e de Qualidade:** verificar dimens√µes, tipos de vari√°veis, dados ausentes e registros duplicados.\n",
    "* **An√°lise Descritiva:** calcular estat√≠sticas b√°sicas e observar uma amostra representativa do conjunto.\n",
    "* **Visualiza√ß√£o de Dados:** criar gr√°ficos que revelam a distribui√ß√£o das vari√°veis e as rela√ß√µes entre elas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3099c6",
   "metadata": {},
   "source": [
    "## üìå An√°lise Estrutural e de Qualidade\n",
    "* **Objetivo:** Ter uma vis√£o geral da estrutura do dataset e verificar a integridade dos dados (nulos e duplicados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1acface",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Dimens√µes do DataFrame\n",
    "print(f\"O dataset possui {df.shape[0]} linhas e {df.shape[1]} colunas.\\n\")\n",
    "\n",
    "# 2. An√°lise de Tipos de Dados e Valores Nulos\n",
    "print(\"An√°lise de tipos de dados e valores nulos por coluna:\")\n",
    "info_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Tipo de Dado\": df.dtypes,\n",
    "        \"Valores Nulos\": df.isnull().sum(),\n",
    "        \"% Nulos\": (df.isnull().sum() / df.shape[0]) * 100,\n",
    "    }\n",
    ")\n",
    "display(info_df.sort_values(by=\"% Nulos\", ascending=False))\n",
    "\n",
    "# 3. Verifica√ß√£o de Linhas Duplicadas\n",
    "num_duplicates = df.duplicated().sum()\n",
    "if num_duplicates > 0:\n",
    "    print(f\"\\n‚ùå Alerta: Foram encontradas {num_duplicates} linhas duplicadas.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Nenhuma linha duplicada foi encontrada no dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdb3aed",
   "metadata": {},
   "source": [
    "### üìã An√°lise dos Resultados\n",
    "\n",
    "#### **Inspe√ß√£o Inicial:**\n",
    "\n",
    "A an√°lise estrutural, realizada com os comandos `.shape`, `.info()` e `.duplicated()`, revelou as seguintes conclus√µes:\n",
    "\n",
    "* **Dimens√µes:** Temos 1100 registros distribu√≠dos em 21 colunas.\n",
    "* **Valores Ausentes:** N√£o encontramos nenhum valor nulo no dataset. Isso nos poupa da necessidade de aplicar t√©cnicas de imputa√ß√£o de dados.\n",
    "* **Registros Duplicados:** N√£o h√° linhas duplicadas. Cada registro √© √∫nico, o que garante a integridade da nossa base.\n",
    "* **Tipos de Dados:** Todas as colunas j√° est√£o em formato num√©rico (`int64`). Isso simplifica bastante o pr√©-processamento, j√° que n√£o precisaremos fazer encoding de vari√°veis categ√≥ricas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f87ead",
   "metadata": {},
   "source": [
    "## üìå An√°lise Descritiva\n",
    "* **Objetivo:** Analisar uma pequena amostra dos dados (5 primeiras linhas do dataset) para entender a natureza das colunas e, em seguida, obter um resumo estat√≠stico das vari√°veis num√©ricas, como m√©dia, desvio padr√£o, m√≠nimo e m√°ximo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67526760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Amostra dos Dados\n",
    "print(\"As 5 primeiras linhas do dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "# 2. Estat√≠sticas Descritivas\n",
    "print(\"\\nResumo estat√≠stico das vari√°veis num√©ricas:\")\n",
    "descriptive_stats = df.describe().T\n",
    "display(descriptive_stats.style.format(\"{:.2f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b72636",
   "metadata": {},
   "source": [
    "### üìã An√°lise dos Resultados\n",
    "\n",
    "#### **An√°lise de Outliers e Natureza das Vari√°veis:**\n",
    "\n",
    "A an√°lise das estat√≠sticas descritivas (`.describe()`) nos permite entender a natureza das nossas vari√°veis:\n",
    "\n",
    "* **Natureza Ordinal:** A maioria das features s√£o ordinais, representando escalas fixas ‚Äî geralmente de 0 a 5.\n",
    "* **Tratamento de Outliers:** Considerando que os valores nos extremos dessas escalas (como 0 ou 5) s√£o respostas v√°lidas e representam os limites das op√ß√µes dispon√≠veis para os estudantes, a aplica√ß√£o de t√©cnicas de remo√ß√£o de outliers seria inadequada. Tais valores s√£o fundamentais para o modelo entender os diferentes n√≠veis de estresse.\n",
    "* **Decis√£o:** Nenhuma a√ß√£o de tratamento de outliers ser√° realizada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bad3e6",
   "metadata": {},
   "source": [
    "## üìå Visualiza√ß√£o de dados\n",
    "* **Objetivo:** Extrair insights sobre as distribui√ß√µes de dados e as rela√ß√µes entre os fatores pesquisados e o n√≠vel de estresse dos estudantes.\n",
    "\n",
    "**Nesta subse√ß√£o, exploraremos:**\n",
    "* A distribui√ß√£o da nossa vari√°vel alvo (stress_level) para verificar o balanceamento entre as classes.\n",
    "* A distribui√ß√£o individual de cada feature preditiva.\n",
    "* A rela√ß√£o entre cada feature e a vari√°vel alvo. \n",
    "* Uma matriz de correla√ß√£o para identificar rela√ß√µes lineares entre as vari√°veis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004943c4",
   "metadata": {},
   "source": [
    "### üîé Distribui√ß√£o da Vari√°vel Alvo\n",
    "\n",
    "* **Objetivo:** Verificar a distribui√ß√£o da vari√°vel alvo  `stress_level` com o intuito de identificar se as classes (0: baixo, 1: m√©dio, 2: alto) est√£o balanceadas. Um desbalanceamento severo poderia enviesar o modelo, fazendo-o performar melhor para as classes mais frequentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feba18ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√£o da √°rea de plotagem\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Gr√°fico de contagem para a vari√°vel alvo\n",
    "sns.countplot(\n",
    "    data=df,\n",
    "    x=TARGET_VARIABLE,\n",
    "    hue=TARGET_VARIABLE,\n",
    "    palette=\"viridis\",\n",
    "    order=[0, 1, 2],\n",
    "    legend=False,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "# Adiciona r√≥tulos de contagem sobre as barras\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, padding=3, fontsize=11)\n",
    "\n",
    "# T√≠tulos e r√≥tulos\n",
    "ax.set_title(\"Distribui√ß√£o dos N√≠veis de Estresse (Vari√°vel Alvo)\", fontsize=16, pad=20)\n",
    "ax.set_xlabel(\"N√≠vel de Estresse (0: Baixo, 1: M√©dio, 2: Alto)\", fontsize=12)\n",
    "ax.set_ylabel(\"Contagem de Estudantes\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242df6b8",
   "metadata": {},
   "source": [
    "#### üìã An√°lise dos Resultados\n",
    "\n",
    "##### **Conclus√£o sobre a Vari√°vel-Alvo**\n",
    "A distribui√ß√£o de stress_level mostra um balanceamento excelente entre as tr√™s classes:\n",
    "\n",
    "* **Baixo (0):** 373 registros\n",
    "* **M√©dio (1):** 358 registros\n",
    "* **Alto (2):** 369 registros\n",
    "\n",
    "Essa distribui√ß√£o equilibrada √© ideal para o treinamento do modelo de classifica√ß√£o. N√£o precisaremos aplicar t√©cnicas de balanceamento de classes, o que simplifica nosso pipeline e evita poss√≠veis vieses artificiais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7751afa",
   "metadata": {},
   "source": [
    "### üîé An√°lise Univariada\n",
    "\n",
    "* **Objetivo:** Visualizar a distribui√ß√£o de cada vari√°vel preditiva para entender o perfil geral das respostas dos estudantes. Como a maioria das vari√°veis √© ordinal (escalas de 0 a 5), gr√°ficos de contagem s√£o ideais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043b49ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica as features preditivas (excluindo a vari√°vel alvo)\n",
    "features = df.drop(TARGET_VARIABLE, axis=1).columns.tolist()\n",
    "\n",
    "# Define a estrutura da grade de visualiza√ß√£o\n",
    "n_cols = 3\n",
    "n_rows = (len(features) + n_cols - 1) // n_cols\n",
    "\n",
    "# Cria a figura e os eixos para os subplots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 4.5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Gera um gr√°fico de contagem para cada feature\n",
    "for i, feature in enumerate(features):\n",
    "    ax = axes[i]\n",
    "    titulo_grafico = FEATURE_TRANSLATOR.get(feature, feature)\n",
    "\n",
    "    sns.countplot(\n",
    "        x=feature, data=df, ax=ax, palette=\"plasma\", hue=feature, legend=False\n",
    "    )\n",
    "    ax.set_title(f\"Distribui√ß√£o de '{titulo_grafico}'\", fontsize=12, weight=\"bold\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"Contagem\")\n",
    "\n",
    "# Oculta eixos n√£o utilizados\n",
    "for i in range(len(features), len(axes)):\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout(pad=2.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1567b287",
   "metadata": {},
   "source": [
    "#### üìã An√°lise dos Resultados\n",
    "\n",
    "##### **Observa√ß√µes Gerais e Conclus√µes da An√°lise Univariada:**\n",
    "\n",
    "Os gr√°ficos de distribui√ß√£o revelam um retrato multifacetado dos estudantes. Vamos explorar os principais achados por categoria:\n",
    "\n",
    "**1. Fatores Acad√™micos e de Carreira:**\n",
    "* **`Desempenho Acad√™mico`**: A autoavalia√ß√£o de desempenho se concentra no n√≠vel 2 (regular). Poucos se classificam no n√≠vel mais baixo, e uma parcela relevante se avalia nos n√≠veis altos (4 e 5). Isso sugere que o desempenho acad√™mico pode n√£o estar t√£o atrelado ao estresse quanto imaginamos.\n",
    "* **`Carga de Estudos`**: A percep√ß√£o de carga de estudos est√° concentrada nos n√≠veis intermedi√°rios a altos (picos em 2 e 3). Tudo indica um ambiente acad√™mico exigente e uma press√£o constante.\n",
    "* **`Rela√ß√£o Professor-Aluno`**: O pico no n√≠vel 2 sugere que a rela√ß√£o com professores √© vista como funcional ou neutra. A baixa frequ√™ncia nos extremos (0 e 5) indica mais dist√¢ncia do que conex√£o forte ou conflito aberto.\n",
    "* **`Preocupa√ß√µes com a Carreira`**: As preocupa√ß√µes com a carreira se concentram em intensidade baixa a moderada (picos em 1 e 2). N√£o parece ser o principal vetor de ansiedade comparado a outros fatores.\n",
    "* **`Atividades Extracurriculares`**: A maioria participa de alguma atividade extracurricular, com destaque para o n√≠vel 2. Isso pode estar relacionado √† sobrecarga de compromissos e ao sono insuficiente.\n",
    "\n",
    "**2. Fatores Psicol√≥gicos e de Sa√∫de Mental:**\n",
    "* **`Hist√≥rico de Sa√∫de Mental`**: A distribui√ß√£o √© praticamente 50/50 entre estudantes com e sem hist√≥rico cl√≠nico de sa√∫de mental. Esse equil√≠brio √© importante ‚Äî n√£o temos uma classe minorit√°ria aqui.\n",
    "* **`N√≠vel de Ansiedadel` e `N√≠vel de Depress√£o`**: Distribui√ß√µes amplas, sem picos definidos. Isso confirma a heterogeneidade da amostra: temos desde estudantes assintom√°ticos at√© aqueles com sintomas severos. O modelo precisar√° lidar com esse espectro completo.\n",
    "* **`N√≠vel de Autoestima`**: A tend√™ncia geral √© de autoestima moderada a alta, com concentra√ß√£o em escores acima de 15. O pico not√°vel no n√≠vel 25 pode indicar um subgrupo com autoconfian√ßa particularmente elevada ‚Äî ou talvez seja apenas um artefato da escala de medi√ß√£o. \n",
    "\n",
    "**3. Fatores Sociais e de Relacionamento:**\n",
    "* **`Suporte Social`**: A distribui√ß√£o bimodal √© reveladora: h√° dois grupos distintos e igualmente expressivos. Um percebe o apoio social como forte (pico no 3), enquanto o outro o considera insuficiente (pico no 1). O suporte social claramente n√£o √© uniforme nesta amostra.\n",
    "* **`Frequ√™ncia de Bullying`**: A distribui√ß√£o indica que o Frequ√™ncia de Bullying √© prevalente. O pico no n√≠vel 1 e as baixas ocorr√™ncias no n√≠vel 0 sugerem que a maioria j√° sofreu algum tipo de Frequ√™ncia de Bullying, ainda que de baixa intensidade.O pico no n√≠vel 1 e as baixas ocorr√™ncias no n√≠vel 0 sugerem que a maioria dos estudantes j√° sofreu algum tipo de Frequ√™ncia de Bullying, ainda que de baixa intensidade.\n",
    "* **`Press√£o dos Colegas`**: A press√£o dos colegas √© percebida com intensidade moderada (pico no 2) ‚Äî presente, mas n√£o extrema, no cotidiano dos estudantes.\n",
    "\n",
    "**4. Fatores de Bem-Estar e Ambiente:**\n",
    "* **`Condi√ß√µes de Moradia`**: Concentra√ß√£o nos n√≠veis intermedi√°rios (2, 3 e 4). A maioria n√£o enfrenta priva√ß√µes severas nem vive em abund√¢ncia ‚Äî um perfil socioecon√¥mico intermedi√°rio.\n",
    "* **`Sensa√ß√£o de Seguran√ßa` e `Atendimento de Necessidades B√°sicas`**: A grande maioria se sente segura e com necessidades b√°sicas atendidas, mas a percep√ß√£o √© mais \"razo√°vel\" (pico no 2) do que \"excelente\". A quase aus√™ncia de respostas no n√≠vel 0 √© um sinal positivo.\n",
    "* **`N√≠vel de Ru√≠do`**: Concentra√ß√£o nos n√≠veis intermedi√°rios. Ambientes perfeitamente silenciosos n√£o s√£o a realidade para a maioria.\n",
    "* **`Qualidade do Sono`**: Aqui temos um ponto cr√≠tico de aten√ß√£o. A forte concentra√ß√£o em n√≠veis baixos, com pico expressivo no n√≠vel 1, indica que sono de m√° qualidade √© uma experi√™ncia comum e prevalente neste grupo.\n",
    "\n",
    "**5. Sintomas Fisiol√≥gicos:**\n",
    "* **`Press√£o Sangu√≠nea`**: Um indicador preocupante. A tend√™ncia de eleva√ß√£o √© clara, com quase metade dos estudantes no n√≠vel mais alto. Um forte sinal de alerta que pode estar ligado ao estresse cr√¥nico.\n",
    "* **`Frequ√™ncia de Dor de Cabe√ßa` e `Problemas Respirat√≥rios`**: Estes s√£o sintomas cr√¥nicos para a maioria. A baixa contagem no n√≠vel 0 (aus√™ncia de sintomas) √© reveladora: dores de cabe√ßa e dificuldades respirat√≥rias parecem normalizadas nesta popula√ß√£o.\n",
    "\n",
    "\n",
    "##### **Perfil do Estudante T√≠pico**\n",
    "\n",
    "Consolidando os achados, temos um retrato preocupante:\n",
    "O estudante m√©dio desta amostra vive uma rotina acad√™mica exigente, com autoavalia√ß√£o de desempenho apenas regular. Sintomas f√≠sicos cr√¥nicos ‚Äî dores de cabe√ßa, problemas respirat√≥rios e, mais alarmante, press√£o arterial elevada ‚Äî s√£o comuns. A m√° qualidade do sono √© realidade para a grande maioria.\n",
    "O ambiente social traz desafios pr√≥prios. O Frequ√™ncia de Bullying √© uma experi√™ncia prevalente, e o suporte social √© polarizado: ou √© forte, ou √© insuficiente. O estudante t√≠pico vive em contexto socioecon√¥mico intermedi√°rio, com necessidades b√°sicas atendidas, mas lida com uma carga de estudos e atividades que pode estar contribuindo para seu esgotamento f√≠sico e mental.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9dc186",
   "metadata": {},
   "source": [
    "### üîé An√°lise Bivariada\n",
    "\n",
    "* **Objetivo:** Investigar como cada vari√°vel preditiva se relaciona com a nossa vari√°vel alvo, `stress_level`. Isso nos ajudar√° a identificar quais fatores parecem ter maior influ√™ncia sobre o estresse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f76de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reutiliza a lista de features e a grade de visualiza√ß√£o da c√©lula anterior\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, n_rows * 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Itera sobre cada feature para criar os gr√°ficos\n",
    "for i, feature in enumerate(features):\n",
    "    ax = axes[i]\n",
    "    titulo_traduzido = FEATURE_TRANSLATOR.get(feature, feature)\n",
    "\n",
    "    # Cria o gr√°fico de contagem, segmentado pela vari√°vel alvo\n",
    "    sns.countplot(x=feature, data=df, hue=TARGET_VARIABLE, ax=ax, palette=\"viridis\")\n",
    "\n",
    "    # Configura√ß√µes do gr√°fico\n",
    "    ax.set_title(\n",
    "        f\"'{titulo_traduzido}' vs. N√≠vel de Estresse\", fontsize=13, weight=\"bold\"\n",
    "    )\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"Contagem\")\n",
    "    ax.legend(title=\"N√≠vel de Estresse\")\n",
    "\n",
    "# Oculta eixos n√£o utilizados\n",
    "for ax in axes[len(features) :]:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout(pad=2.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325543d6",
   "metadata": {},
   "source": [
    "#### üìã An√°lise dos Resultados\n",
    "\n",
    "##### **Observa√ß√µes Gerais e Conclus√µes da An√°lise Bivariada:**\n",
    "\n",
    "Nesta etapa, cruzamos cada vari√°vel preditiva com a nossa vari√°vel alvo (`N√≠vel de Estresse`) para identificar padr√µes e a for√ßa da rela√ß√£o entre elas. Vari√°veis que mostram uma mudan√ßa clara na distribui√ß√£o do estresse s√£o fortes candidatas a serem bons preditores para o modelo de Machine Learning.\n",
    "\n",
    "**1. Fatores Acad√™micos e de Carreira:**\n",
    "* **`Desempenho Acad√™mico`**: A **correla√ß√£o negativa √© muito clara**. Estudantes com performance alta (n√≠veis 4 e 5) apresentam predominantemente estresse baixo, enquanto estresse m√©dio e alto s√£o raros. Um forte preditor inverso.\n",
    "* **`Carga de Estudos`**: Confirma-se uma **forte correla√ß√£o positiva**. Quanto maior a carga de estudos, maior a propor√ß√£o de estresse elevado.\n",
    "* **`Rela√ß√£o Professor-Aluno`**: Existe uma **correla√ß√£o negativa vis√≠vel**. Rela√ß√µes melhores com professores est√£o associadas a menos estresse alto. Um efeito protetor interessante.\n",
    "* **`Preocupa√ß√µes com a Carreira` e `Atividades Extracurriculares`**: Ambas demonstram uma **forte correla√ß√£o positiva**. Mais preocupa√ß√£o com o futuro e maior envolvimento em atividades extracurriculares aparecem ligados a n√≠veis mais altos de estresse.\n",
    "\n",
    "**2. Fatores Psicol√≥gicos e de Sa√∫de Mental:**\n",
    "* **`N√≠vel de Ansiedadel` e `N√≠vel de Depress√£o`**: Como esperado, ambos mostram uma **correla√ß√£o positiva fort√≠ssima e linear**. Nos n√≠veis baixos dessas escalas, o estresse √© praticamente inexistente. Nos n√≠veis altos, o estresse elevado domina por completo. Essas ser√£o, provavelmente, as vari√°veis mais influentes do modelo.\n",
    "* **`N√≠vel de Autoestima`**: Apresenta uma **correla√ß√£o negativa muito clara**. Quanto maior a autoestima, menor o n√≠vel de estresse.\n",
    "* **`Hist√≥rico de Sa√∫de Mental`**: Sendo bin√°ria, essa vari√°vel mostra seu poder de forma direta. Quem tem hist√≥rico de problemas de sa√∫de mental apresenta propor√ß√£o **significativamente maior** de estresse elevado.\n",
    "\n",
    "**3. Fatores Sociais e de Relacionamento:**\n",
    "* **`Suporte Social`**: A an√°lise revela uma rela√ß√£o n√£o linear interessante: O pico de estresse alto ocorre no n√≠vel 1 (suporte insuficiente/insatisfat√≥ria), sendo at√© mais alto que no n√≠vel 0 (aus√™ncia total de suporte). Parece que perceber um suporte \"falho\" √© mais estressante do que n√£o ter suporte nenhum. De modo geral, por√©m, a tend√™ncia √© de **forte correla√ß√£o negativa**.\n",
    "* **`Frequ√™ncia de Bullying`**: Uma das **correla√ß√µes positivas mais fortes**. A propor√ß√£o de estresse alto cresce de forma alarmante com o aumento do Frequ√™ncia de Bullying.\n",
    "* **`Press√£o dos Colegas`**: Mostra uma **correla√ß√£o positiva moderada**. A press√£o dos colegas aumenta o estresse, mas de forma menos acentuada que o Frequ√™ncia de Bullying.\n",
    "\n",
    "**4. Fatores de Bem-Estar e Ambiente:**\n",
    "* **`Condi√ß√µes de Moradia`, `Sensa√ß√£o de Seguran√ßa`, `Atendimento de Necessidades B√°sicas` e `Qualidade do Sono`**: Todas mostram **correla√ß√£o negativa consistente**. Melhores condi√ß√µes de vida, maior seguran√ßa, necessidades b√°sicas bem atendidas e maior qualidade de sono est√£o claramente associadas a n√≠veis mais baixos de estresse.\n",
    "* **`N√≠vel de Ru√≠do`**: **Correla√ß√£o positiva forte**. Mais barulho, mais estresse.\n",
    "\n",
    "**5. Sintomas Fisiol√≥gicos:**\n",
    "* **`Frequ√™ncia de Dor de Cabe√ßa` e `Problemas Respirat√≥rios`**: Ambas t√™m uma **correla√ß√£o positiva muito forte**. A maior frequ√™ncia desses sintomas est√° diretamente ligada a uma maior propor√ß√£o de estresse alto.\n",
    "* **`Press√£o Sangu√≠nea`**: A rela√ß√£o √© **extremamente forte e praticamente determin√≠stica**. Estresse alto est√° concentrado quase exclusivamente no grupo com maior n√≠vel de press√£o arterial. Um divisor de √°guas claro entre as classes.\n",
    "\n",
    "\n",
    "##### **Ranking de Preditores Potenciais**\n",
    "\n",
    "A an√°lise bivariada mostrou que o dataset possui uma boa variedade de preditores. A maioria das vari√°veis apresenta uma rela√ß√£o clara com o n√≠vel de estresse, o que √© um sinal positivo para a modelagem. Com base na for√ßa e na clareza dessas rela√ß√µes, √© poss√≠vel organizar as vari√°veis da seguinte maneira:\n",
    "\n",
    "* **Preditores de Primeira Ordem (Rela√ß√£o Extremamente Forte):**\n",
    "    * `N√≠vel de Ansiedadel`, `N√≠vel de Depress√£o`: Quase proxies do pr√≥prio estresse.\n",
    "    * `Press√£o Sangu√≠nea`: Divisor de √°guas entre as classes.\n",
    "    * `Frequ√™ncia de Bullying`, `Suporte Social`, `N√≠vel de Autoestima`: Fatores psicossociais com impacto massivo.\n",
    "\n",
    "* **Preditores de Segunda Ordem (Rela√ß√£o Forte e Consistente):**\n",
    "    * `Desempenho Acad√™mico`, `Carga de Estudos`: A dupla central da vida acad√™mica.\n",
    "    * `Qualidade do Sono`: Fator de bem-estar fundamental.\n",
    "    * `Frequ√™ncia de Dor de Cabe√ßa`, `Problemas Respirat√≥rios`: Sintomas f√≠sicos associados.\n",
    "    * `Preocupa√ß√µes com a Carreira`, `Hist√≥rico de Sa√∫de Mental`: Indicadores de preocupa√ß√£o e predisposi√ß√£o.\n",
    "\n",
    "* **Preditores de Terceira Ordem (Rela√ß√£o Clara, por√©m mais Moderada):**\n",
    "    * `Condi√ß√µes de Moradia`, `Sensa√ß√£o de Seguran√ßa`, `Atendimento de Necessidades B√°sicas`: Base do bem-estar.\n",
    "    * `Rela√ß√£o Professor-Aluno`, `Press√£o dos Colegas`, `Atividades Extracurriculares`, `N√≠vel de Ru√≠do`: Vari√°veis contextuais moduladoras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758c01e1",
   "metadata": {},
   "source": [
    "### üîé An√°lise Multivariada: Matriz de Correla√ß√£o\n",
    "\n",
    "* **Objetivo:** Visualizar a correla√ß√£o linear entre todas as vari√°veis num√©ricas do dataset por meio de um mapa de calor (heatmap), permitindo obter uma vis√£o quantitativa da intensidade e da dire√ß√£o das rela√ß√µes lineares entre os pares de vari√°veis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661725a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. C√°lculo e Tradu√ß√£o da Matriz\n",
    "corr_matrix = df.corr()\n",
    "translated_corr_matrix = corr_matrix.rename(\n",
    "    columns=FEATURE_TRANSLATOR, index=FEATURE_TRANSLATOR\n",
    ")\n",
    "\n",
    "# 2. Visualiza√ß√£o do Heatmap\n",
    "plt.figure(figsize=(18, 15))\n",
    "ax = sns.heatmap(\n",
    "    translated_corr_matrix,\n",
    "    annot=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    fmt=\".2f\",\n",
    "    linewidths=0.5,\n",
    ")\n",
    "plt.title(\"Matriz de Correla√ß√£o entre Todas as Vari√°veis\", fontsize=16, weight=\"bold\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# 3. Destaque da Vari√°vel Alvo nos Eixos\n",
    "translated_target_name = FEATURE_TRANSLATOR.get(TARGET_VARIABLE, TARGET_VARIABLE)\n",
    "for label in ax.get_yticklabels() + ax.get_xticklabels():\n",
    "    if label.get_text() == translated_target_name:\n",
    "        label.set_weight(\"bold\")\n",
    "        label.set_color(\"firebrick\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 4. Listagem Ordenada da Correla√ß√£o com a Vari√°vel Alvo\n",
    "print(f\"\\nCorrela√ß√£o das Vari√°veis com '{translated_target_name}':\")\n",
    "correlation_with_target = (\n",
    "    corr_matrix[TARGET_VARIABLE].rename(FEATURE_TRANSLATOR).sort_values(ascending=False)\n",
    ")\n",
    "print(correlation_with_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaa9fd2",
   "metadata": {},
   "source": [
    "#### üìã An√°lise dos Resultados\n",
    "\n",
    "##### **Correla√ß√£o com a Vari√°vel Alvo (`N√≠vel de Estresse`)**\n",
    "\n",
    "A lista ordenada de correla√ß√µes confirma numericamente o que vimos nos gr√°ficos. Podemos dividir os achados em dois grupos principais:\n",
    "\n",
    "* **Correla√ß√µes Positivas (Fatores de Risco)**:\n",
    "    * As vari√°veis com os maiores valores positivos, como **`Frequ√™ncia de Bullying` (0.75)**, **`Preocupa√ß√µes com a Carreira` (0.74)**, **`N√≠vel de Ansiedadel` (0.74)** e **`N√≠vel de Depress√£o` (0.73)**, s√£o os indicadores mais fortes de estresse. Quanto maior o valor dessas vari√°veis, maior o n√≠vel de estresse.\n",
    "\n",
    "* **Correla√ß√µes Negativas (Fatores de Prote√ß√£o)**:\n",
    "    * As vari√°veis com os valores negativos mais fortes, como **`N√≠vel de Autoestima` (-0.76)**, **`Qualidade do Sono` (-0.75)**, **`Desempenho Acad√™mico` (-0.72)** e **`Sensa√ß√£o de Seguran√ßa` (-0.71)**, atuam como protetores. Valores mais altos est√£o fortemente associados a menos estresse.\n",
    "\n",
    "**Conclus√£o**: A an√°lise quantitativa valida completamente nossas observa√ß√µes visuais da an√°lise bivariada. Temos um conjunto robusto de features com forte poder preditivo.\n",
    "\n",
    "##### **Multicolinearidade entre Features**\n",
    "\n",
    "Olhando o heatmap, buscamos correla√ß√µes fortes entre as pr√≥prias vari√°veis preditoras (fora da linha/coluna `N√≠vel de Estresse`). Multicolinearidade ocorre quando duas features medem essencialmente a mesma coisa, o que pode inflar artificialmente a import√¢ncia de vari√°veis ou dificultar a interpreta√ß√£o dos resultados.\n",
    "\n",
    "Alguns pontos de aten√ß√£o:\n",
    "\n",
    "* **`Atendimento de Necessidades B√°sicas` e `Sensa√ß√£o de Seguran√ßa` (0.82)**: Correla√ß√£o muito alta. Faz sentido: a percep√ß√£o de seguran√ßa est√° diretamente ligada ao atendimento de necessidades b√°sicas.\n",
    "* **`Frequ√™ncia de Bullying` e `N√≠vel de Ansiedadel` (0.71)**: Alta correla√ß√£o, sugerindo que experi√™ncias de Frequ√™ncia de Bullying andam de m√£os dadas com n√≠veis elevados de ansiedade.\n",
    "* **`N√≠vel de Autoestima` e `Qualidade do Sono` (0.69)**: Correla√ß√£o forte e interessante: melhor autoestima parece estar ligada a melhor qualidade de sono.\n",
    "\n",
    "**Decis√£o T√©cnica**: Embora existam pontos de multicolinearidade, os modelos que pretendemos testar inicialmente (como Random Forest) s√£o robustos a esse fen√¥meno. Seguindo o princ√≠pio da simplicidade (**YAGNI** - *You Aren't Gonna Need It*), **manteremos todas as features por enquanto**. Essa an√°lise fica registrada caso seja necess√°rio refinar o modelo em ciclos futuros de otimiza√ß√£o.\n",
    "\n",
    "##### **Conclus√µes Finais da EDA**\n",
    "\n",
    "Conclu√≠mos esta fase com as seguintes pontos:\n",
    "1.  O dataset √© de **alta qualidade**, sem dados ausentes ou duplicados.\n",
    "2.  A vari√°vel alvo, `N√≠vel de Estresse`, est√° **bem balanceada**.\n",
    "3.  Existem **muitas features com forte correla√ß√£o** (positiva e negativa) com o estresse, indicando grande potencial preditivo.\n",
    "4.  Identificamos a presen√ßa de **multicolinearidade**, mas optamos por n√£o tratar neste momento para manter a simplicidade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd0ec90",
   "metadata": {},
   "source": [
    "# 4. üßπ Pr√©-processamento e Prepara√ß√£o dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bd92f2",
   "metadata": {},
   "source": [
    "Com base nas conclus√µes da An√°lise Explorat√≥ria, nosso dataset j√° est√° limpo e todas as vari√°veis s√£o num√©ricas. Portanto, o pr√©-processamento ser√° focado nas seguintes etapas essenciais:\n",
    "* **Separa√ß√£o de Features e Alvo:** Dividimos nosso DataFrame em X (matriz de features, ou vari√°veis preditoras) e y (vetor alvo, a vari√°vel que queremos prever).\n",
    "* **Divis√£o em Conjuntos de Treino e Teste:** Separamos os dados em dois conjuntos: um para treinamento (80% dos dados), utilizado para ensinar o modelo, e outro para teste (20% dos dados), empregado para avaliar seu desempenho em dados in√©ditos. Utilizamos a estratifica√ß√£o (stratify=y) para garantir que a propor√ß√£o das classes de estresse fosse mantida em ambos os conjuntos, o que √© essencial para datasets balanceados como o nosso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7591357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as features (X) e a vari√°vel alvo (y) usando a constante global\n",
    "# CORRE√á√ÉO: Utiliza a vari√°vel `TARGET_VARIABLE` em vez da string \"TARGET_VARIABLE\"\n",
    "X = df.drop(TARGET_VARIABLE, axis=1)\n",
    "y = df[TARGET_VARIABLE]\n",
    "\n",
    "# Exibe as dimens√µes para verifica√ß√£o\n",
    "print(f\"Dimens√µes de X (features): {X.shape}\")\n",
    "print(f\"Dimens√µes de y (alvo): {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05308ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa os dados para treinar o modelo e para avali√°-lo em dados n√£o vistos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,  # 20% dos dados para o conjunto de teste\n",
    "    random_state=RANDOM_STATE,  # Garante reprodutibilidade\n",
    "    stratify=y,  # Mant√©m a propor√ß√£o das classes nos dois conjuntos\n",
    ")\n",
    "\n",
    "# Verifica as dimens√µes dos conjuntos resultantes\n",
    "print(f\"Dimens√µes de X_train: {X_train.shape}\")\n",
    "print(f\"Dimens√µes de X_test:  {X_test.shape}\")\n",
    "print(f\"Dimens√µes de y_train: {y_train.shape}\")\n",
    "print(f\"Dimens√µes de y_test:  {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac43fd8",
   "metadata": {},
   "source": [
    "# 5. ü§ñ Modelagem e Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78468ca9",
   "metadata": {},
   "source": [
    "Nesta fase, iniciaremos o processo de constru√ß√£o de modelos de Machine Learning para prever o n√≠vel de estresse dos estudantes.Nossa estrat√©gia ser√° divida nas seguintes etapas:\n",
    "* Criar uma Fun√ß√£o de Avalia√ß√£o\n",
    "* Estabelecer um Baseline\n",
    "* Treinar Modelos Candidatos: Decision Tree e Random Forest\n",
    "* Ao final, comparamos o desempenho dos tr√™s modelos para selecionar o melhor candidato."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2b415d",
   "metadata": {},
   "source": [
    "## üìå Criar uma Fun√ß√£o de Avalia√ß√£o\n",
    "* **Objetivo:** Para evitar a repeti√ß√£o de c√≥digo, criamos uma fun√ß√£o auxiliar (evaluate_model) que calcula e exibe as principais m√©tricas de desempenho (acur√°cia, relat√≥rio de classifica√ß√£o) e a matriz de confus√£o para qualquer modelo treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868fe620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Realiza previs√µes, calcula e exibe as m√©tricas de avalia√ß√£o e a matriz de confus√£o.\n",
    "\n",
    "    Args:\n",
    "        model: O modelo treinado a ser avaliado.\n",
    "        X_test: Dados de teste (features).\n",
    "        y_test: Dados de teste (alvo).\n",
    "        model_name (str): Nome do modelo para usar nos t√≠tulos.\n",
    "    \"\"\"\n",
    "    # 1. Realiza previs√µes\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # 2. Calcula e exibe a acur√°cia\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"--- Avalia√ß√£o: {model_name} ---\")\n",
    "    print(f\"Acur√°cia: {accuracy:.2%}\\n\")\n",
    "\n",
    "    # 3. Exibe o relat√≥rio de classifica√ß√£o\n",
    "    print(\"Relat√≥rio de Classifica√ß√£o:\")\n",
    "    class_names = [\"Baixo\", \"M√©dio\", \"Alto\"]\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "\n",
    "    # 4. Exibe a matriz de confus√£o\n",
    "    print(\"Matriz de Confus√£o:\")\n",
    "    ConfusionMatrixDisplay.from_estimator(\n",
    "        model, X_test, y_test, display_labels=class_names\n",
    "    )\n",
    "    plt.title(f\"Matriz de Confus√£o - {model_name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd943d4f",
   "metadata": {},
   "source": [
    "## üìå Estabelecer um Baseline\n",
    "* **Objetivo:** Treinamos um DummyClassifier, um modelo simples que faz previs√µes baseadas na distribui√ß√£o das classes. Ele nos d√° um ponto de refer√™ncia: qualquer modelo mais complexo precisa ter um desempenho superior ao dele para ser considerado √∫til."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fec54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instancia e treina o modelo baseline\n",
    "baseline_model = DummyClassifier(strategy=\"stratified\", random_state=RANDOM_STATE)\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# 2. Avalia o modelo usando a fun√ß√£o auxiliar\n",
    "evaluate_model(baseline_model, X_test, y_test, \"Modelo Baseline (Dummy Classifier)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1418dc4",
   "metadata": {},
   "source": [
    "## üìå Modelo 1: Decision Tree\n",
    "* **Objetivo:** Com o baseline estabelecido, vamos agora treinar nosso primeiro modelo preditivo real. Decision tree √© um modelo interpret√°vel que aprende regras de decis√£o a partir dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ded946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instancia e treina o modelo\n",
    "tree_model = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# 2. Avalia o modelo\n",
    "evaluate_model(tree_model, X_test, y_test, \"√Årvore de Decis√£o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd8754c",
   "metadata": {},
   "source": [
    "## üìå Modelo 2: Random Forest\n",
    "* **Objetivo:** O modelo de √Årvore de Decis√£o entregou um √≥timo resultado. Agora, vamos dar um passo al√©m e testar o Random Forest ‚Äî um modelo de ensemble que combina v√°rias √°rvores para gerar previs√µes mais consistentes e reduzir o risco de overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c525d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instancia e treina o modelo\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 2. Avalia o modelo\n",
    "evaluate_model(rf_model, X_test, y_test, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37ca4ca",
   "metadata": {},
   "source": [
    "## üìå Compara√ß√£o dos Modelos e Escolha Final\n",
    "\n",
    "Ap√≥s treinar e avaliar tr√™s modelos distintos, podemos comparar seus resultados de acur√°cia para selecionar o mais perform√°tico.\n",
    "\n",
    "| Modelo | Acur√°cia no Conjunto de Teste |\n",
    "| :--- | :--- |\n",
    "| Baseline (Dummy Classifier) | 35% |\n",
    "| √Årvore de Decis√£o | 85% |\n",
    "| **Random Forest** | **89%** |\n",
    "\n",
    "### Modelo Escolhido\n",
    "\n",
    "Depois de comparar os modelos, o **Random Forest Classifier** se destacou como a melhor escolha para este projeto. Tr√™s raz√µes principais:\n",
    "1. **Acur√°cia mais alta:** Atingiu 89%, o melhor resultado entre todos os modelos testados.\n",
    "2. **Equil√≠brio entre as classes:** O `f1-score` m√©dio foi superior e mais bem distribu√≠do, indicando que o modelo n√£o favorece uma classe em detrimento de outra.\n",
    "3. **Maior confiabilidade:** Por ser um ensemble, o Random Forest tende a generalizar melhor que uma √°rvore isolada, oferecendo previs√µes mais est√°veis em dados novos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd713897",
   "metadata": {},
   "source": [
    "# 6. üõ†Ô∏è Otimiza√ß√£o de Hiperpar√¢metros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5441f5",
   "metadata": {},
   "source": [
    "O Random Forest apresentou o melhor desempenho com seus par√¢metros padr√£o (como n_estimators=100). Embora seja poss√≠vel ir al√©m e ajustar hiperpar√¢metros ‚Äî testando diferentes n√∫meros de √°rvores, profundidades m√°ximas, crit√©rios de divis√£o, entre outros ‚Äî por meio de t√©cnicas como Grid Search ou Random Search com valida√ß√£o cruzada, optamos por n√£o realizar essa etapa aqui.\n",
    "Para o escopo atual, o desempenho do modelo j√° √© excelente e atende aos objetivos do projeto. Caso seja necess√°rio espremer mais alguns pontos percentuais de performance no futuro, a otimiza√ß√£o de hiperpar√¢metros seria o pr√≥ximo passo natural."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66c1039",
   "metadata": {},
   "source": [
    "# 7. üèÅ Conclus√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f958f",
   "metadata": {},
   "source": [
    "## üìå Exporta√ß√£o\n",
    "A √∫ltima etapa do nosso pipeline de desenvolvimento √© salvar (ou \"serializar\") o objeto do modelo treinado em um arquivo. Isso nos permite recarregar o modelo treinado em outros ambientes ou aplica√ß√µes ‚Äî como nosso dashboard em Streamlit ‚Äî sem a necessidade de refazer todo o processo de treinamento. Utilizamos a biblioteca `joblib` para esta tarefa, que √© eficiente para salvar objetos Python que cont√™m grandes arrays de dados, como os modelos do Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56104d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o caminho e garante que o diret√≥rio exista\n",
    "model_dir = \"../models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model_path = os.path.join(model_dir, \"student_stress_rf_model.joblib\")\n",
    "\n",
    "# Salva o objeto do modelo no arquivo\n",
    "joblib.dump(rf_model, model_path)\n",
    "\n",
    "print(f\"‚úÖ Modelo Random Forest salvo com sucesso em: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eed5991",
   "metadata": {},
   "source": [
    "## üìå Resumo do Projeto\n",
    "Percorremos todo o ciclo de um projeto de Machine Learning: desde a explora√ß√£o inicial dos dados at√© a cria√ß√£o e exporta√ß√£o de um modelo preditivo funcional.\n",
    "### Principais Conclus√µes\n",
    "* O dataset √© limpo e bem estruturado ‚Äî n√£o tivemos que lidar com valores ausentes, o que acelerou bastante o processo.\n",
    "* A an√°lise explorat√≥ria mostrou que a vari√°vel alvo est√° razoavelmente balanceada e que v√°rias features possuem correla√ß√£o significativa com os n√≠veis de estresse.\n",
    "* O Random Forest alcan√ßou uma acur√°cia consideravelmente alta e desempenho superior tanto ao baseline quanto √† √Årvore de Decis√£o individual. Isso sugere que os padr√µes nos dados s√£o complexos e se beneficiam de uma abordagem ensemble.\n",
    "* O modelo final foi salvo com sucesso e est√° pronto para ser integrado em aplica√ß√µes que realizem previs√µes em tempo real."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tech-challenge-machine-learning-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
